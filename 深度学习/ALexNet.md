⌚2012:NeurIPS [@krizhevskyImageNetClassificationDeep2017]
##### 👀研究背景
此前图像分类多依赖人工设计特征（如 SIFT、HOG）+ 传统分类器，对大规模复杂数据集（如 ImageNet，含 120 万张图片、1000 个类别）的识别精度极低；浅层神经网络则存在梯度消失、训练效率低等问题，AlexNet 通过**深度 CNN + 工程优化**首次实现了大规模图像的高精度分类。
##### 💡核心方法
共**8 层可训练层**（5 层卷积层 + 3 层全连接层）。
- 卷积层（5 层）：逐步提取从低级（边缘、纹理）到高级（形状、物体部件）的图像特征，配合**重叠最大池化**（池化步长小于核大小）提升特征提取的丰富性；
- 全连接层（3 层）：将卷积提取的二维特征展平为一维向量，通过全连接映射到 1000 个输出节点，最后经**Softmax 激活函数**输出每个类别的概率；
- 输出层：对应 ImageNet 的 1000 个物体类别，实现图像的多分类。
##### 🎨关键创新
- 用**ReLU 激活函数**替代传统的 Sigmoid/Tanh：解决了深层网络中的**梯度消失**问题，同时 ReLU 计算速度更快，大幅提升训练效率；
- 引入**Dropout 正则化**：随机失活部分神经元（论文中全连接层失活概率 0.5），有效防止大规模网络的**过拟合**；
- **双 GPU 并行训练**：将网络和数据拆分到两个 GPU 上并行计算，解决了单 GPU 的内存和计算量瓶颈，能处理更大的模型和数据集；
##### 🚀实验结果
- 在 ILSVRC2012 比赛中，AlexNet 的**Top-5 错误率仅为 15.3%**，远超第二名传统机器学习方法的 26.2%；
- 在 ImageNet 数据集的 1000 类分类任务中，首次证明了深度 CNN 在大规模图像识别中的有效性。
##### 📈影响
- 训练数据是通过原始图片训练网络，开启了**端到端深度学习**的 CV 新时代，CNN 成为图像识别、检测、分割等任务的基础；
- 证明了深度神经网络在大规模任务中的可行性。
