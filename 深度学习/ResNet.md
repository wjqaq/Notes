⌚2016:CVPR[@heDeepResidualLearning2015]
##### 👀研究背景
- **退化问题**：随着网络层数增加，**训练集准确率先上升后下降**，测试集准确率同步下降，且并非过拟合导致（过拟合表现为训练集准确率高、测试集低）；
- **梯度消失 / 爆炸**：早期深层网络训练困难的表面原因，可通过**批归一化（BN）**、权重初始化等方法有效缓解，但 BN 无法解决退化问题 —— 这说明退化是深层网络的**本质学习问题**，而非数值计算问题。
##### 💡核心方法


##### 🎨关键创新


##### 🚀实验结果


##### 📈影响