---
date: 2026-01-13T22:33:00
---
## 多模态

#### ViT（Vision Transformer，ICLR 2021）
#### 👀研究背景
1. Transformer在NLP邻域取得革命性成功，但是Transformer的全局注意力机制尚未在计算机视觉中成为主流；
2. 传统CNN依赖局部池化和卷积，建模**长距离依赖**能力有限，且存在**归纳偏置**的约束；
3. 此前尝试多为CNN-Transformer混合架构，未能充分发挥纯Transformer的全局建模能力；
#### 💡核心方法
1. **图像序列化**：将图像分割为patch（16 $\times$ 16 或者 32 $\times$ 32），展平为序列token

