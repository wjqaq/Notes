⌚1998：Proceedings of the IEEE
##### 👀研究背景
- 传统模式识别依赖手工设计的特征提取器，需针对每个任务重新设计，耗时且泛化能力有限。
- 手写字符、文档等识别任务中，数据存在高维性、平移 / 变形 variability，现有方法难以兼顾准确性和效率。
- 多模块识别系统（如分割、识别、语言建模）通常单独训练，难以优化全局性能。

##### 💡核心方法
![](assets/LeNet（CNN）/file-20260204170502289.png)

| 层级  |   类型    |      参数设置       |   输出尺寸   |
| :-: | :-----: | :-------------: | :------: |
| 输入  |  原始图像   |    32×32 像素     |  32×32   |
| C1  |   卷积层   |    6个5×5卷积核     | 28×28×6  |
| S2  | 子采样（池化） |    2×2 平均池化     | 14×14×6  |
| C3  |   卷积层   |  16个卷积核（部分连接）   | 10×10×16 |
| S4  |   子采样   |    2×2 平均池化     |  5×5×16  |
| C5  |   卷积层   | 120个全连接卷积核（5×5） | 1×1×120  |
| F6  |  全连接层   |    120 → 84     |    84    |
| 输出  | RBF输出单元 |     10类数字识别     |    10    |

- 卷积神经网络（LeNet-5）：采用 “卷积层 + 下采样层” 交替结构，结合全连接层和 RBF 输出层，直接处理像素级输入。
- 梯度基学习：通过反向传播算法计算梯度，使用随机梯度下降（SGD）优化损失函数，支持全局训练。
- 图变换器网络（GTN）：将多模块系统建模为图变换过程，实现分割、识别等模块的联合训练。
- 空间位移神经网络（SDNN）：通过复制卷积网络扫描输入，避免显式字符分割。

给定输入图像 $n_h、n_w$，卷积核$k_h、k_w$，padding$p_h、p_w$以及步幅$s_h、s_w$其输出形状为：
$$
\lfloor (n_h - k_h + p_h + s_h) / s_h  \rfloor \times \lfloor (n_w - k_w + p_w + s_w) / s_w  \rfloor
$$
